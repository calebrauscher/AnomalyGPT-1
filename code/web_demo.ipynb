{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gradio as gr\n",
    "import mdtex2html\n",
    "from model.openllama import OpenLLAMAPEFTModel\n",
    "import torch\n",
    "from io import BytesIO\n",
    "from PIL import Image as PILImage\n",
    "import cv2\n",
    "import numpy as np\n",
    "from matplotlib import pyplot as plt\n",
    "from torchvision import transforms\n",
    "\n",
    "# init the model\n",
    "args = {\n",
    "    'model': 'openllama_peft',\n",
    "    'imagebind_ckpt_path': '../pretrained_ckpt/imagebind_ckpt/imagebind_huge.pth',\n",
    "    'vicuna_ckpt_path': '../pretrained_ckpt/vicuna_ckpt/7b_v0',\n",
    "    'anomalygpt_ckpt_path': './ckpt/train_supervised/pytorch_model.pt',\n",
    "    'delta_ckpt_path': '../pretrained_ckpt/pandagpt_ckpt/7b/pytorch_model.pt',\n",
    "    'stage': 2,\n",
    "    'max_tgt_len': 128,\n",
    "    'lora_r': 32,\n",
    "    'lora_alpha': 32,\n",
    "    'lora_dropout': 0.1\n",
    "}\n",
    "\n",
    "model = OpenLLAMAPEFTModel(**args)\n",
    "delta_ckpt = torch.load(args['delta_ckpt_path'], map_location=torch.device('cpu'))\n",
    "model.load_state_dict(delta_ckpt, strict=False)\n",
    "delta_ckpt = torch.load(args['anomalygpt_ckpt_path'], map_location=torch.device('cpu'))\n",
    "model.load_state_dict(delta_ckpt, strict=False)\n",
    "model = model.eval().half().cuda()\n",
    "\n",
    "\n",
    "\"\"\"Override Chatbot.postprocess\"\"\"\n",
    "def postprocess(self, y):\n",
    "    if y is None:\n",
    "        return []\n",
    "    for i, (message, response) in enumerate(y):\n",
    "        y[i] = (\n",
    "            None if message is None else mdtex2html.convert((message)),\n",
    "            None if response is None else mdtex2html.convert(response),\n",
    "        )\n",
    "    return y\n",
    "\n",
    "\n",
    "gr.Chatbot.postprocess = postprocess\n",
    "\n",
    "\n",
    "def parse_text(text):\n",
    "    \"\"\"copy from https://github.com/GaiZhenbiao/ChuanhuChatGPT/\"\"\"\n",
    "    lines = text.split(\"\\n\")\n",
    "    lines = [line for line in lines if line != \"\"]\n",
    "    count = 0\n",
    "    for i, line in enumerate(lines):\n",
    "        if \"```\" in line:\n",
    "            count += 1\n",
    "            items = line.split('`')\n",
    "            if count % 2 == 1:\n",
    "                lines[i] = f'<pre><code class=\"language-{items[-1]}\">'\n",
    "            else:\n",
    "                lines[i] = f'<br></code></pre>'\n",
    "        else:\n",
    "            if i > 0:\n",
    "                if count % 2 == 1:\n",
    "                    line = line.replace(\"`\", \"\\`\")\n",
    "                    line = line.replace(\"<\", \"&lt;\")\n",
    "                    line = line.replace(\">\", \"&gt;\")\n",
    "                    line = line.replace(\" \", \"&nbsp;\")\n",
    "                    line = line.replace(\"*\", \"&ast;\")\n",
    "                    line = line.replace(\"_\", \"&lowbar;\")\n",
    "                    line = line.replace(\"-\", \"&#45;\")\n",
    "                    line = line.replace(\".\", \"&#46;\")\n",
    "                    line = line.replace(\"!\", \"&#33;\")\n",
    "                    line = line.replace(\"(\", \"&#40;\")\n",
    "                    line = line.replace(\")\", \"&#41;\")\n",
    "                    line = line.replace(\"$\", \"&#36;\")\n",
    "                lines[i] = \"<br>\"+line\n",
    "    text = \"\".join(lines)\n",
    "    return text\n",
    "\n",
    "\n",
    "def predict(\n",
    "    input, \n",
    "    image_path, \n",
    "    normal_img_path,  \n",
    "    chatbot, \n",
    "    max_length, \n",
    "    top_p, \n",
    "    temperature, \n",
    "    history, \n",
    "    modality_cache, \n",
    "):\n",
    "    \n",
    "    if image_path is None and normal_img_path is None:\n",
    "        return [(input, \"There is no input data provided! Please upload your data and start the conversation.\")]\n",
    "    else:\n",
    "        print(f'[!] image path: {image_path}\\n[!] normal image path: {normal_img_path}\\n')\n",
    "\n",
    "    # prepare the prompt\n",
    "    prompt_text = ''\n",
    "    for idx, (q, a) in enumerate(history):\n",
    "        if idx == 0:\n",
    "            prompt_text += f'{q}\\n### Assistant: {a}\\n###'\n",
    "        else:\n",
    "            prompt_text += f' Human: {q}\\n### Assistant: {a}\\n###'\n",
    "    if len(history) == 0:\n",
    "        prompt_text += f'{input}'\n",
    "    else:\n",
    "        prompt_text += f' Human: {input}'\n",
    "\n",
    "    response, pixel_output = model.generate({\n",
    "        'prompt': prompt_text,\n",
    "        'image_paths': [image_path] if image_path else [],\n",
    "        'normal_img_paths': [normal_img_path] if normal_img_path else [],\n",
    "        'audio_paths': [],\n",
    "        'video_paths': [],\n",
    "        'thermal_paths': [],\n",
    "        'top_p': top_p,\n",
    "        'temperature': temperature,\n",
    "        'max_tgt_len': max_length,\n",
    "        'modality_embeds': modality_cache\n",
    "    },web_demo=True)\n",
    "    chatbot.append((parse_text(input), parse_text(response)))\n",
    "    history.append((input, response))\n",
    "\n",
    "\n",
    "    plt.imshow(pixel_output.to(torch.float16).reshape(224,224).detach().cpu(), cmap='binary_r')\n",
    "    plt.axis('off')\n",
    "    plt.savefig('output.png',bbox_inches='tight',pad_inches = 0)\n",
    "\n",
    "    target_size = 224\n",
    "    original_width, original_height = PILImage.open(image_path).size\n",
    "    if original_width > original_height:\n",
    "        new_width = target_size\n",
    "        new_height = int(target_size * (original_height / original_width))\n",
    "    else:\n",
    "        new_height = target_size\n",
    "        new_width = int(target_size * (original_width / original_height))\n",
    "\n",
    "    new_image = PILImage.new('L', (target_size, target_size), 255)  # 'L' mode for grayscale\n",
    "\n",
    "    paste_x = (target_size - new_width) // 2\n",
    "    paste_y = (target_size - new_height) // 2\n",
    "\n",
    "    pixel_output = PILImage.open('output.png').resize((new_width, new_height), PILImage.LANCZOS)\n",
    "\n",
    "    new_image.paste(pixel_output, (paste_x, paste_y))\n",
    "\n",
    "    new_image.save('output.png')\n",
    "\n",
    "    image = cv2.imread('output.png', cv2.IMREAD_GRAYSCALE)\n",
    "    kernel = np.ones((3, 3), np.uint8)\n",
    "    eroded_image = cv2.erode(image, kernel, iterations=1)\n",
    "    cv2.imwrite('output.png', eroded_image)\n",
    "\n",
    "    output =  PILImage.open('output.png').convert('L')\n",
    "\n",
    "\n",
    "    return chatbot, history, modality_cache, output\n",
    "\n",
    "\n",
    "\n",
    "def reset_user_input():\n",
    "    return gr.update(value='')\n",
    "\n",
    "\n",
    "def reset_state():\n",
    "    return gr.update(value=''), None, None, [], [], [], PILImage.open('ffffff.png')\n",
    "\n",
    "\n",
    "\n",
    "with gr.Blocks() as demo:\n",
    "    gr.HTML(\"\"\"<h1 align=\"center\">Demo of AnomalyGPT</h1>\"\"\")\n",
    "\n",
    "    with gr.Row():\n",
    "        with gr.Column(scale=1):\n",
    "            with gr.Row(scale=3):\n",
    "                image_path = gr.Image(type=\"filepath\", label=\"Query Image\", value=None)\n",
    "            with gr.Row(scale=3):\n",
    "                normal_img_path = gr.Image(type=\"filepath\", label=\"Normal Image (optional)\", value=None)\n",
    "            with gr.Row():\n",
    "                max_length = gr.Slider(0, 512, value=512, step=1.0, label=\"Maximum length\", interactive=True)\n",
    "            with gr.Row():\n",
    "                top_p = gr.Slider(0, 1, value=0.01, step=0.01, label=\"Top P\", interactive=True)\n",
    "            with gr.Row():\n",
    "                temperature = gr.Slider(0, 1, value=1.0, step=0.01, label=\"Temperature\", interactive=True)\n",
    "\n",
    "\n",
    "        with gr.Column(scale=3):\n",
    "            with gr.Row():\n",
    "                with gr.Column(scale=6):\n",
    "                    chatbot = gr.Chatbot().style(height=415)\n",
    "                with gr.Column(scale=4):\n",
    "                    # gr.Image(output)\n",
    "                    image_output = gr.Image(interactive=False, label=\"Localization Output\", every=1.0, shape=[224,224], type='pil',value=PILImage.open('ffffff.png'))\n",
    "            with gr.Row():\n",
    "                user_input = gr.Textbox(show_label=False, placeholder=\"Input...\", lines=10).style(container=False)\n",
    "            with gr.Row():\n",
    "                with gr.Column(scale=2):\n",
    "                    submitBtn = gr.Button(\"Submit\", variant=\"primary\")\n",
    "                with gr.Column(scale=1):\n",
    "                    emptyBtn = gr.Button(\"Clear History\")\n",
    "                    \n",
    "    history = gr.State([])\n",
    "    modality_cache = gr.State([])\n",
    "\n",
    "    submitBtn.click(\n",
    "        predict, [\n",
    "            user_input, \n",
    "            image_path, \n",
    "            normal_img_path, \n",
    "            chatbot, \n",
    "            max_length, \n",
    "            top_p, \n",
    "            temperature, \n",
    "            history, \n",
    "            modality_cache,\n",
    "        ], [\n",
    "            chatbot, \n",
    "            history,\n",
    "            modality_cache,\n",
    "            image_output\n",
    "        ],\n",
    "        show_progress=True\n",
    "    )\n",
    "\n",
    "    submitBtn.click(reset_user_input, [], [user_input])\n",
    "    emptyBtn.click(reset_state, outputs=[\n",
    "        user_input,\n",
    "        image_path,\n",
    "        normal_img_path,\n",
    "        chatbot, \n",
    "        history, \n",
    "        modality_cache,\n",
    "        image_output\n",
    "    ], show_progress=True)\n",
    "\n",
    "\n",
    "demo.queue().launch()"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
